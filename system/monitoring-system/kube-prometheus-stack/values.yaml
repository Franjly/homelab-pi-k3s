kube-prometheus-stack:
  ## Create default rules for monitoring the cluster
  ##
  defaultRules:
    create: true
    rules:
      alertmanager: true
      etcd: true
      configReloaders: true
      general: true
      k8s: true
      kubeApiserverAvailability: true
      kubeApiserverBurnrate: true
      kubeApiserverHistogram: true
      kubeApiserverSlos: true
      kubeControllerManager: true
      kubelet: true
      kubeProxy: true
      kubePrometheusGeneral: true
      kubePrometheusNodeRecording: true
      kubernetesApps: true
      kubernetesResources: true
      kubernetesStorage: true
      kubernetesSystem: true
      kubeScheduler: true
      kubeStateMetrics: true
      network: true
      node: true
      nodeExporterAlerting: true
      nodeExporterRecording: true
      prometheus: true
      prometheusOperator: true

  ## Custom rules for TrueNAS
  ##
  additionalPrometheusRulesMap:
    rule-name:
      groups:
      - name: truenas-netdata
        rules:
          - alert: node_high_cpu_usage_70
            expr: sum(sum_over_time(netdata_system_cpu_percentage_average{dimension=~"(user|system|softirq|irq|guest)"}[10m])) by (job) / sum(count_over_time(netdata_system_cpu_percentage_average{dimension="idle"}[10m])) by (job) > 70
            for: 1m
            annotations:
              description: '{{ $labels.job }} on ''{{ $labels.job }}'' CPU usage is at {{ humanize $value }}%.'
              summary: CPU alert for container node '{{ $labels.job }}'
          - alert: node_high_memory_usage_70
            expr: 100 / sum(netdata_system_ram_MB_average) by (job) * sum(netdata_system_ram_MB_average{dimension=~"free|cached"}) by (job) < 30
            for: 1m
            annotations:
              description: '{{ $labels.job }} memory usage is {{ humanize $value}}%.'
              summary: Memory alert for container node '{{ $labels.job }}'
          - alert: node_low_root_filesystem_space_20
            expr: 100 / sum(netdata_disk_space_GB_average{family="/"}) by (job) * sum(netdata_disk_space_GB_average{family="/",dimension=~"avail|cached"}) by (job) < 20
            for: 1m
            annotations:
              description: '{{ $labels.job }} root filesystem space is {{ humanize $value}}%.'
              summary: Root filesystem alert for container node '{{ $labels.job }}'
          - alert: node_root_filesystem_fill_rate_6h
            expr: predict_linear(netdata_disk_space_GB_average{family="/",dimension=~"avail|cached"}[1h], 6 * 3600) < 0
            for: 1h
            labels:
              severity: critical
            annotations:
              description: Container node {{ $labels.job }} root filesystem is going to fill up in 6h.
              summary: Disk fill alert for Swarm node '{{ $labels.job }}'


  ## Configuration for alertmanager
  ## ref: https://prometheus.io/docs/alerting/alertmanager/
  ##
  alertmanager:
    enabled: true

    config:
      global:
        resolve_timeout: 5m
      inhibit_rules:
        - source_matchers:
            - 'severity = critical'
          target_matchers:
            - 'severity =~ warning|info'
          equal:
            - 'namespace'
            - 'alertname'
        - source_matchers:
            - 'severity = warning'
          target_matchers:
            - 'severity = info'
          equal:
            - 'namespace'
            - 'alertname'
        - source_matchers:
            - 'alertname = InfoInhibitor'
          target_matchers:
            - 'severity = info'
          equal:
            - 'namespace'
      route:
        group_by: ['namespace']
        group_wait: 30s
        group_interval: 5m
        repeat_interval: 12h
        receiver: 'discord_webhook'
        routes:
        - receiver: 'null'
          matchers:
            - alertname =~ "InfoInhibitor|Watchdog"
      receivers:
      - name: 'null'
      - name: 'discord_webhook'
        webhook_configs:
        - url: 'http://alertmanager-discord.monitoring-system.svc.cluster.local:9094'
      templates:
      - '/etc/alertmanager/config/*.tmpl'

    ingress:
      enabled: true

      ingressClassName: nginx

      annotations:
        cert-manager.io/cluster-issuer: letsencrypt-staging
        # kubernetes.io/tls-acme: "true"
        # hajimari.io/appName: AlertManager
        # hajimari.io/icon: chart-bar
      hosts:
        - alertmanager.local.tecno-fly.com
      paths:
        - /
      tls: 
        - secretName: alertmanager-tls
          hosts:
          - alertmanager.local.tecno-fly.com
    
    alertmanagerSpec:
      storage:
        volumeClaimTemplate:
          spec:
            storageClassName: longhorn
            resources:
              requests:
                storage: 25Gi

  grafana:
    enabled: true

    defaultDashboardsTimezone: Europe/Madrid

    adminUser: <path:pi-k3s/data/system/monitoring-system/grafana#admin-user>
    adminPassword: <path:pi-k3s/data/system/monitoring-system/grafana#admin-passwd>

    ingress:
      enabled: true

      ingressClassName: nginx

      annotations:
        cert-manager.io/cluster-issuer: letsencrypt-staging
        # kubernetes.io/tls-acme: "true"
        # hajimari.io/appName: Grafana
        # hajimari.io/icon: chart-bar
      hosts:
        - grafana.local.tecno-fly.com
      path: /
      tls:
        - secretName: grafana-tls
          hosts:
          - grafana.local.tecno-fly.com

    persistence:
      enabled: false
      storageClassName: longhorn
      size: 10Gi

    sidecar:
      dashboards:
        enabled: true
        label: grafana_dashboard
        labelValue: "1"
        folder: /tmp/dashboards

        ## Annotations for Grafana dashboard configmaps
        ##
        annotations:
          k8s-sidecar-target-directory: /tmp/dashboards/kubernetes

        multicluster:
          global:
            enabled: false
          etcd:
            enabled: false
        provider:
          allowUiUpdates: false
          foldersFromFilesStructure: true
          
      datasources:
        enabled: true
        defaultDatasourceEnabled: true

        uid: prometheus

        ## URL of prometheus datasource
        ##
        # url: http://prometheus-stack-prometheus:9090/

        # If not defined, will use prometheus.prometheusSpec.scrapeInterval or its default
        # defaultDatasourceScrapeInterval: 15s

        ## Annotations for Grafana datasource configmaps
        ##
        annotations: {}

        ## Create datasource for each Pod of Prometheus StatefulSet;
        ## this uses headless service `prometheus-operated` which is
        ## created by Prometheus Operator
        ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/0fee93e12dc7c2ea1218f19ae25ec6b893460590/pkg/prometheus/statefulset.go#L255-L286
        createPrometheusReplicasDatasources: false
        label: grafana_datasource
        labelValue: "1"

        ## Field with internal link pointing to existing data source in Grafana.
        ## Can be provisioned via additionalDataSources
        exemplarTraceIdDestinations: {}
          # datasourceUid: Jaeger
          # traceIdLabelName: trace_id

    plugins:
      - grafana-piechart-panel
      - grafana-clock-panel

    extraConfigmapMounts: []
    # - name: certs-configmap
    #   mountPath: /etc/grafana/ssl/
    #   configMap: certs-configmap
    #   readOnly: true

    deleteDatasources: []
    # - name: example-datasource
    #   orgId: 1

    ## Configure additional grafana datasources (passed through tpl)
    ## ref: http://docs.grafana.org/administration/provisioning/#datasources
    additionalDataSources:
      - name: Loki
        type: loki
        uid: loki
        url: http://loki.monitoring-system:3100
        isDefault: false

    # envFromSecret: grafana-secrets

    ## Configure grafana dashboard providers
    ## ref: http://docs.grafana.org/administration/provisioning/#dashboards
    ##
    ## `path` must be /var/lib/grafana/dashboards/<provider_name>
    ##
    dashboardProviders: 
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
        - name: 'loki'
          orgId: 1
          folder: 'Loki'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/loki
        - name: 'unifi-poller'
          orgId: 1
          folder: 'UniFi-Poller'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/unifi-poller
        - name: 'ingress-nginx'
          orgId: 1
          folder: 'NGINX Ingress'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/ingress-nginx
        - name: 'pi-hole'
          orgId: 1
          folder: 'Pi-hole'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/pi-hole
        - name: 'calico'
          orgId: 1
          folder: 'Calico'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/calico
        - name: 'cert-manager'
          orgId: 1
          folder: 'Cert-Manager'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/cert-manager
        - name: 'longhorn'
          orgId: 1
          folder: 'Longhorn'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/longhorn
        - name: 'velero'
          orgId: 1
          folder: 'Velero'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/velero
        - name: 'argocd'
          orgId: 1
          folder: 'ArgoCD'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/argocd
        - name: 'truenas'
          orgId: 1
          folder: 'TrueNAS'
          type: file
          disableDeletion: true
          editable: true
          options:
            path: /var/lib/grafana/dashboards/truenas

    ## Configure grafana dashboard to import
    ## NOTE: To use dashboards you must also enable/configure dashboardProviders
    ## ref: https://grafana.com/dashboards
    ##
    ## dashboards per provider, use provider name as key.
    ##
    dashboards:
      loki:
        loki-dashboard:
          url: https://raw.githubusercontent.com/Franjly/grafana-dashboards-pi-k3s/main/loki/loki-dashboard.json
          datasource: prometheus
      unifi-poller:
        USG-Insights:
          gnetId: 11313
          revision: 8
          datasource: prometheus
        USW-Insights:
          gnetId: 11312
          revision: 8
          datasource: prometheus
        UAP-Insights:
          gnetId: 11314
          revision: 9
          datasource: prometheus
        Client-Insights:
          gnetId: 11315
          revision: 8
          datasource: prometheus
        Network-Sites:
          gnetId: 11311
          revision: 4
          datasource: prometheus
        Client-DPI:
          gnetId: 11310
          revision: 4
          datasource: prometheus
      ingress-nginx:
        Kubernetes-Nginx-Ingress-Controller:
          gnetId: 14314
          revision: 2
          datasource: prometheus
        NGINX-Ingress-Controller:
          url: https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/grafana/dashboards/nginx.json
          datasource: prometheus
        Request-Handling-Performance:
          url: https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/grafana/dashboards/request-handling-performance.json
          datasource: prometheus
      pi-hole:
        PI-Hole-Exporter:
          url: https://raw.githubusercontent.com/eko/pihole-exporter/master/grafana/dashboard.json
          datasource: prometheus
      calico:
        Felix-Dashboard:
          gnetId: 12175
          revision: 5
          datasource: prometheus
        Kubernetes-Calico:
          url: https://raw.githubusercontent.com/Franjly/grafana-dashboards-pi-k3s/main/calico/kubernetes-calico.json
          datasource: prometheus
      cert-manager:
        cert-manager-dashboard:
          url: https://raw.githubusercontent.com/Franjly/grafana-dashboards-pi-k3s/main/cert-manager/cert-manager-dashboard.json
          datasource: prometheus
      velero:
        velero-dashboard:
          url: https://raw.githubusercontent.com/Franjly/grafana-dashboards-pi-k3s/main/velero/velero-dashboard,json
          datasource: prometheus
      longhorn:
        longhorn-dashboard:
          url: https://raw.githubusercontent.com/Franjly/grafana-dashboards-pi-k3s/main/longhorn/longhorn-dashboard.json
          datasource: prometheus
      argocd:
        argocd-dashboard:
          url: https://raw.githubusercontent.com/Franjly/grafana-dashboards-pi-k3s/main/argocd/argocd-dashboard.json
          datasource: prometheus
      truenas:
        truenas-netdata:
          url: https://raw.githubusercontent.com/Franjly/grafana-dashboards-pi-k3s/main/truenas/netdata.json
          datasource: prometheus

        # custom-dashboard:
        #   file: dashboards/custom-dashboard.json
        # prometheus-stats:
        #   gnetId: 2
        #   revision: 2
        #   datasource: Prometheus
        # local-dashboard:
        #   url: https://example.com/repository/test.json
        #   token: ''
        # local-dashboard-base64:
        #   url: https://example.com/repository/test-b64.json
        #   token: ''
        #   b64content: true
        # local-dashboard-gitlab:
        #   url: https://example.com/repository/test-gitlab.json
        #   gitlabToken: ''
        # local-dashboard-bitbucket:
        #   url: https://example.com/repository/test-bitbucket.json
        #   bearerToken: ''

    grafana.ini:
      server:
        root_url: https://grafana.local.tecno-fly.com
      # auth.generic_oauth:
      #   enabled: true
      #   allow_sign_up: true
      #   name: Dex
      #   client_id: grafana-sso
      #   client_secret: $__env{GRAFANA_SSO_CLIENT_SECRET}
      #   scopes: openid profile email groups
      #   auth_url: https://dex.khuedoan.com/auth
      #   token_url: https://dex.khuedoan.com/token
      #   api_url: https://dex.khuedoan.com/userinfo

  kubeControllerManager:
    enabled: true

    endpoints:
    - 192.168.30.10

    service:
      enabled: true
      port: 10257
      targetPort: 10257
      selector:
        component: kube-controller-manager

    serviceMonitor:
      enabled: true
      https: true
      insecureSkipVerify: true

  kubeScheduler:
    enabled: true

    endpoints:
    - 192.168.30.10

    service:
      enabled: true
      port: 10259
      targetPort: 10259
      selector:
        component: kube-scheduler

    serviceMonitor:
      enabled: true
      https: true
      insecureSkipVerify: true

  kubeProxy:
    enabled: true

    endpoints:
    - 192.168.30.10
    - 192.168.30.20
    - 192.168.30.21

    service:
      enabled: true
      port: 10249
      targetPort: 10249
      selector:
        k8s-app: kube-proxy

    serviceMonitor:
      enabled: true
      https: false

  prometheus:
    enabled: true

    ingress:
      enabled: true

      ingressClassName: nginx

      annotations:
        cert-manager.io/cluster-issuer: letsencrypt-staging
        # kubernetes.io/tls-acme: "true"
        # hajimari.io/appName: Prometheus
        # hajimari.io/icon: chart-bar
      hosts:
        - prometheus.local.tecno-fly.com
      paths:
        - /
      tls: 
        - secretName: prometheus-tls
          hosts:
            - prometheus.local.tecno-fly.com

    prometheusSpec:
      ruleSelectorNilUsesHelmValues: false
      serviceMonitorSelectorNilUsesHelmValues: false
      podMonitorSelectorNilUsesHelmValues: false
      probeSelectorNilUsesHelmValues: false
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: longhorn
            resources:
              requests:
                storage: 100Gi
      additionalScrapeConfigs:
        - job_name: 'truenas-netdata'
          scrape_interval: 1m
          metrics_path: '/api/v1/allmetrics'
          params:
            format: [prometheus]
          honor_labels: true
          static_configs:
          - targets: ['192.168.40.250:19999']
        - job_name: 'truenas-graphite'
          scrape_interval: 1m
          metrics_path: '/metrics'
          static_configs:
          - targets: ['192.168.40.250:9108']